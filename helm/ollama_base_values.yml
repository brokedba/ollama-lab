# Declare ollama-helm  variables to be passed into your templates.

# -- String to partially override template  (will maintain the release name)
nameOverride: ""
# -- String to fully override template
fullnameOverride: ""

# -- Number of replicas
replicaCount: 1

# Knative configuration
knative:
  # -- Enable Knative integration
  enabled: false
  # -- Knative service container concurrency
  containerConcurrency: 0
  # -- Knative service timeout seconds
  timeoutSeconds: 300
  # -- Knative service response start timeout seconds
  responseStartTimeoutSeconds: 300
  # -- Knative service idle timeout seconds
  idleTimeoutSeconds: 300

# Docker image
image:
  # -- Docker image registry
  repository: ollama/ollama

  # -- Docker pull policy
  pullPolicy: IfNotPresent

  # -- Docker image tag, overrides the image tag whose default is the chart appVersion.
  tag: ""

# -- Docker registry secret names as an array
imagePullSecrets:
  - name: dockerhub-sec

###################
#      Pod       #         
###################

# -- Map of annotations to add to the pods
podAnnotations: {}

# -- Map of labels to add to the pods
podLabels: {}

# -- Node labels for pod assignment.
nodeSelector:
  role: ollama

# -- Tolerations for pod assignment
tolerations: []

# -- Affinity for pod assignment
affinity: {}

# -- How to replace existing pods
updateStrategy:
  # -- Can be "Recreate" or "RollingUpdate". Default is RollingUpdate
  type: ""

# -- Topology Spread Constraints for pod assignment
topologySpreadConstraints: {}

#####################
# Ollama parameters #
#####################
ollama:
  gpu:
    # -- Enable GPU integration
    enabled: false
    # -- GPU type: 'nvidia' or 'amd'
    # If 'ollama.gpu.enabled', default value is nvidia (CUDA). If set to 'amd',  'rocm' images will be pulled  
    type: 'nvidia'
    # -- Specify the number of GPU
    number: 1
    # -- only for nvidia cards; change to (example) 'nvidia.com/mig-1g.10gb' to use MIG slice
    nvidiaResource: "nvidia.com/gpu"
    # nvidiaResource: "nvidia.com/mig-1g.10gb" # example

  # -- List of models to pull at container startup
  # models:
  #  - llama2
  #  - mistral
  models: []

  # -- Add insecure flag for pulling at container startup
  insecure: false

  # -- Override ollama-data volume mount path, default: "/root/.ollama"
  mountPath:

# Configure resource requests and limits
# ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources:
  # -- Pod requests
  requests:
    # Memory request
    # memory: 4096Mi

    # CPU request
    cpu: 2000m

  # -- Pod limit
  limits: {}
    # Memory limit
    # memory: 8192Mi

    # CPU limit
    # cpu: 4000m

# -- Additional environments variables on the output Deployment definition.
extraEnv:
  - name: OLLAMA_KEEP_ALIVE
    value: "-1"
  - name: OLLAMA_NUM_PARALLEL
    value: "3"
  - name: OLLAMA_MAX_LOADED_MODELS
    value: "2"
###############################
# Enable Storage persistence  #
###############################
# ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
persistentVolume:
  # -- Enable persistence using PVC
  enabled: true

  # -- Ollama server data Persistent Volume access modes
  # Must match those of existing PV or dynamic provisioner
  # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  accessModes:
    - ReadWriteOnce

  # -- Ollama server data Persistent Volume annotations
  annotations: {}

  # -- If you'd like to bring your own PVC for persisting Ollama state, pass the name of the
  # created + ready PVC here. If set, this Chart will not create the default PVC.
  # Requires server.persistentVolume.enabled: true
  existingClaim: ""

  # -- Ollama server data Persistent Volume size
  size: 30Gi

  # -- Ollama server data Persistent Volume Storage Class
  # If defined, storageClassName: <storageClass>
  # If set to "-", storageClassName: "", which disables dynamic provisioning
  # If undefined (the default) or set to null, no storageClassName spec is
  # set, choosing the default provisioner.  (gp2 on AWS, standard on
  # GKE, AWS & OpenStack)
  storageClass: oci-bv

  # -- Ollama server data Persistent Volume Binding Mode
  # If defined, volumeMode: <volumeMode>
  # If empty (the default) or set to null, no volumeBindingMode spec is
  # set, choosing the default mode.
  volumeMode: ""
  # -- Subdirectory of Ollama server data Persistent Volume to mount
  # Useful if the volume's root directory is not empty
  subPath: ""
  # -- Pre-existing PV to attach this claim to
  # Useful if a CSI auto-provisions a PV for you and you want to always
  # reference the PV moving forward
  volumeName: ""
  
#########################
# Configure Service     #
#########################
service:
  # -- Service type
  type: ClusterIP

  # -- Service port
  port: 11434

  # -- Service node port when service type is 'NodePort'
  nodePort: 31434

  # -- Annotations to add to the service
  annotations: {}
  
##########################
# Configure the ingress  #
##########################
ingress:
  # -- Enable ingress controller resource
  enabled: true

  # -- IngressClass that will be used to implement the Ingress (Kubernetes 1.18+)
  className: "nginx"

  # -- Additional annotations for the Ingress resource.
  annotations:
    kubernetes.io/ingress.class: nginx

  # The list of hostnames to be covered with this ingress record.
  hosts:
    - host: ollama.domain
      paths:
        - path: /
          pathType: Prefix

  # --  The tls configuration for hostnames to be covered with this ingress record.
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local
  
# Configure extra options for liveness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
livenessProbe:
  # -- Enable livenessProbe
  enabled: true

  # -- Request path for livenessProbe
  path: /

  # -- Initial delay seconds for livenessProbe
  initialDelaySeconds: 60

  # -- Period seconds for livenessProbe
  periodSeconds: 10

  # -- Timeout seconds for livenessProbe
  timeoutSeconds: 5

  # -- Failure threshold for livenessProbe
  failureThreshold: 6

  # -- Success threshold for livenessProbe
  successThreshold: 1

# Configure extra options for readiness probe
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
readinessProbe:
  # -- Enable readinessProbe
  enabled: true

  # -- Request path for readinessProbe
  path: /

  # -- Initial delay seconds for readinessProbe
  initialDelaySeconds: 30

  # -- Period seconds for readinessProbe
  periodSeconds: 5

  # -- Timeout seconds for readinessProbe
  timeoutSeconds: 3

  # -- Failure threshold for readinessProbe
  failureThreshold: 6

  # -- Success threshold for readinessProbe
  successThreshold: 1
  
##########################
# Configure autoscaling  #
##########################
autoscaling:
  # -- Enable autoscaling
  enabled: false

  # -- Number of minimum replicas
  minReplicas: 1

  # -- Number of maximum replicas
  maxReplicas: 100

  # -- CPU usage to target replica
  targetCPUUtilizationPercentage: 80

############################
# Volumes and VolumeMounts #
############################
## -- Additional volumes on the output Deployment definition.
volumes: []
# - name: ollama-storage
#   persistentVolumeClaim:
#      claimName: ollama-pvc  # Use the PVC

# -- Additional volumeMounts on the output Deployment definition.

volumeMounts: []
#  - name: ollama-storage
#   mountPath: "/ai_models/ollama"  # Mount the PVC content at this path  # -- targetMemoryUtilizationPercentage: 80

# -- Additional arguments on the output Deployment definition.
extraArgs: []

########################################
# -- Init containers for model preload #
########################################
initContainers:
  - name: install-and-setup-model
    image: python:3.9  # Use an image with Python and pip pre-installed
    command: [sh, -c]
    args:
      - |
        pip install -U "huggingface_hub[cli]";
        mkdir -p /root/.ollama/download;
        huggingface-cli download bartowski/Meta-Llama-3.1-8B-Instruct-GGUF Meta-Llama-3.1-8B-Instruct-Q4_K_S.gguf \
          --local-dir /root/.ollama/download \
          --local-dir-use-symlinks False;
        cat << 'EOF' > /root/.ollama/download/llama31.loc
        FROM /root/.ollama/download/Meta-Llama-3.1-8B-Instruct-Q4_K_S.gguf
        # Set custom parameter values
        PARAMETER temperature 1.0
        PARAMETER num_ctx 4096
        PARAMETER stop "<|start_header_id|>"
        PARAMETER stop "<|end_header_id|>"
        PARAMETER stop "<|eot_id|>"
        # Define the model template
        TEMPLATE """
        {{ "{{" }}- if .System }}<|start_header_id|>system<|end_header_id|>
        {{ "{{" }} .System }}<|eot_id|>{{ "{{" }} end }}{{ "{{" }} if .Prompt }}<|start_header_id|>user<|end_header_id|>
        {{ "{{" }} .Prompt }}<|eot_id|>{{ "{{" }} end }}<|start_header_id|>assistant<|end_header_id|>
        {{ "{{" }} .Response }}<|eot_id|>
        """
        # Set the system message
        SYSTEM You are a helpful AI assistant named e-llmo Assistant.
        EOF
    volumeMounts:
      - name: ollama-data
        mountPath: /root/.ollama  # Use same as default
  ############################################################################      
  # -- Lifecycle for pod assignment (override ollama.models startup pulling) #
  ############################################################################
lifecycle:
  postStart:
    exec:
      command: [ "/bin/sh", "-c", "ollama create llama3.1.8b -f /root/.ollama/download/llama31.loc" ]

###################
# Service account #
###################
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccount:
  # -- Specifies whether a service account should be created
  create: true
  # -- Automatically mount a ServiceAccount's API credentials?
  automount: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Pod Security Context
podSecurityContext: {}
  # fsGroup: 2000

# -- Container Security Context
securityContext: {}
  # capabilities:
  #  drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# -- Specify runtime class
runtimeClassName: ""
# -- Use the host’s ipc namespace.
hostIPC: false

# -- Use the host’s pid namespace
hostPID: false

# -- Use the host's network namespace.
hostNetwork: false
